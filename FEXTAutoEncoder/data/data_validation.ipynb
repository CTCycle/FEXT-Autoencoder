{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# setting warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category = Warning)\n",
    "\n",
    "# add parent folder path to the namespace\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# import modules and components\n",
    "from utils.preprocessing import load_images\n",
    "from utils.validation import DataValidation\n",
    "from config.pathfinder import IMG_DATA_PATH, VAL_PATH\n",
    "import config.configurations as cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validator = DataValidation()\n",
    "\n",
    "# find and assign images path\n",
    "images_paths = []\n",
    "for root, dirs, files in os.walk(IMG_DATA_PATH):\n",
    "    for file in files:\n",
    "        images_paths.append(os.path.join(root, file))\n",
    "\n",
    "# select a fraction of data for training\n",
    "total_samples = cnf.TRAIN_SAMPLES + cnf.TEST_SAMPLES\n",
    "df_images = pd.DataFrame(images_paths, columns=['images path'])\n",
    "df_images = df_images.sample(total_samples, random_state=cnf.seed)\n",
    "\n",
    "# create train and test datasets (for validation)\n",
    "test_data = df_images.sample(n=cnf.TEST_SAMPLES, random_state=cnf.SPLIT_SEED)\n",
    "train_data = df_images.drop(test_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of train samples: {train_data.shape[0]}')\n",
    "print(f'Number of test samples:  {test_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pixel intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test images as numpy arrays\n",
    "train_images = load_images(train_data['images path'], cnf.IMG_SHAPE[:-1], \n",
    "                           as_tensor=False,  normalize=False)\n",
    "test_images = load_images(test_data['images path'], cnf.IMG_SHAPE[:-1], \n",
    "                          as_tensor=False, normalize=False)\n",
    "\n",
    "# validate pixel intensity histograms for both datasets\n",
    "validator.pixel_intensity_histograms(train_images, test_images, VAL_PATH,\n",
    "                                     names=['Train', 'Test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aquarius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
